---
title: "p8105_hw5_mb5357"
author: "Maria Beg"
date: "2025-11-12"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```


## Problem 1


```{r, cache=TRUE}

set.seed(1)

# Function 
birthday_sim <- function(n) {
  birthdays <- sample(1:365, size = n, replace = TRUE)
  any(duplicated(birthdays))
}


# Run 10,000 simulations 
sim_results <- 
  expand_grid(
    group_size = 2:50,
    iter = 1:10000
  ) |>
  mutate(shared = map_lgl(group_size, birthday_sim))


# Compute probability of at least one shared birthday
prob_results <- 
  sim_results |>
  group_by(group_size) |>
  summarize(prob_shared = mean(shared))


# Plot the results
prob_results |>
  ggplot(aes(x = group_size, 
             y = prob_shared)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthdays by Group Size",
    x = "Group Size",
    y = "Probability"
  ) +
  theme_bw()

```


The plot shows that as the group size increases, the likelihood of two people sharing a birthday rises sharply. The probability reaches roughly 50% at a group size of about 23. By the time the group reaches around 50 people, the probability is very high, approaching 1. Overall, the results illustrate how quickly these probabilities grow even with a large number of possible birthdays.



## Problem 2


```{r, cache=TRUE}


# Function to simulate data
sim_one = function(true_mu) {
  x = rnorm(30, mean = true_mu, sd = 5)
  t.test(x, mu = 0) |> 
    broom::tidy() |> 
    select(estimate, p.value)
}


# Simulation
sim_results = 
  expand_grid(
  true_mu = 0:6,
  iter = 1:5000
) |> 
  mutate(out = map(true_mu, sim_one)) |> 
  unnest(out)


# Power Calculation
power_results = sim_results |> 
  group_by(true_mu) |> 
  summarize(power = mean(p.value < 0.05))


```



**Plot 1**

```{r}

power_results |> 
  ggplot(aes(x=true_mu, y=power))+
  geom_line()+
  geom_point()+
  labs(
    title = "Power vs. Effect size",
    x = "True μ",
    y= "Power"
  )+
  theme_bw()

```


The plot shows that the probability of rejecting the null hypothesis (power) increases as the true mean μ grows. For small effect sizes (μ near 0), power is low because the test rarely detects a difference. Power rises rapidly for moderate effect sizes (μ ≈ 2–4) and approaches 1 for larger μ, illustrating that larger true effects are easier to detect with a fixed sample size and variance.


**Plot 2**

```{r}

# Average estimates

est_results = sim_results |> 
  group_by(true_mu) |> 
  summarize(
    avg_est = mean(estimate),
    avg_est_rejected = mean(estimate[p.value < 0.05])
  )


# Plot 2

est_results |> 
  ggplot(aes(x = true_mu)) +
  
  geom_line(aes(y = avg_est, 
                color = "All samples"), size = 1.2) +
  geom_line(aes(y = avg_est_rejected, 
                color = "Rejected samples"), size = 1.2) +
  
  geom_point(aes(y = avg_est), 
             color = "black", size = 2) +
  geom_point(aes(y = avg_est_rejected), 
             color = "black", size = 2) +
  
  scale_color_manual(values = c("All samples" = "blue", 
                                "Rejected samples" = "orange")) +
  
  labs(
    title = "Average estimated μ vs. True μ",
    x = "True μ",
    y = "Average estimate μ",
    color = "Sample type"
  ) +
  
  theme_bw() +
  theme(legend.position = "bottom")

```


The average estimate of μ across all simulations closely matches the true μ. When considering only samples where the null is rejected, the estimate is biased upward, particularly for small true μ. This occurs because rejection is more likely when a sample overestimates μ due to random variation, a form of selection bias. As μ increases, more tests reject the null, and the mean of rejected estimates approaches the true μ.
